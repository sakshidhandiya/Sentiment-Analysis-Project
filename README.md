# Sentiment-Analysis-Project
This project performs sentiment classification using Logistic Regression with L2 regularization and class weight balancing, ensuring robust handling of imbalanced emotion classes. It demonstrates the complete NLP pipeline from preprocessing to model evaluation and visualization.

üìå Overview

This project applies Natural Language Processing (NLP) and Logistic Regression models to classify text into six emotions: anger, fear, happy, love, sadness, and surprise. The pipeline demonstrates text preprocessing, feature engineering, model building with regularization and class weights, evaluation, and visualization.

The focus is to compare model performance across different Logistic Regression configurations:

  No Regularization

  L2 Regularization

  Class Weight Balanced

  L2 Regularization + Class Weight Balanced

üìä Dataset

  Source: Emotion-labeled dataset (Emotion_final.xlsx).

  Size: 17,167 records (train), 4,292 records (test).

  Features:

    Text ‚Äì Input text data

    Emotion ‚Äì Target emotion label

‚öôÔ∏è Methodology

1. Preprocessing

  Tokenization, stopword removal (including high-frequency tokens like feel / feeling).

  Lemmatization using WordNetLemmatizer.

  Feature extraction using TF-IDF vectorization.

  Additional features: polarity & subjectivity from TextBlob.

2. Model Training

  Four logistic regression variants were tested:

    No Regularization

    L2 Regularization

    Class Weight Balanced

    L2 Regularization + Class Weight Balanced

3. Evaluation Metrics

  Precision, Recall, F1-score (per class).

  Overall Accuracy (train and test sets).

  Macro and Weighted averages for fair comparison.

üìà Results

üîπ Logistic Regression (No Regularization)

  Training Accuracy: 95%

  Testing Accuracy: 86%

Observations:

Strong recall for happy (0.96) and sadness (0.94).

Weaker performance for love (recall 0.62) and surprise (recall 0.47).

Indicates model struggles with minority/imbalanced classes.

üîπ Logistic Regression (L2 Regularization)

  Training Accuracy: 95%

  Testing Accuracy: 86%

Observations:

Results nearly identical to no regularization.

Regularization helped control overfitting but did not significantly improve class imbalance.

üîπ Logistic Regression (Class Weight Balanced)

  Training Accuracy: 94%

  Testing Accuracy: 88%

Observations:

Significant improvement in love (recall: 0.91 vs 0.62 earlier).

Surprise also improved (recall: 0.86 vs 0.47 earlier).

Slight drop in happy precision (0.94) but better balance overall.

üîπ Logistic Regression (L2 Regularization + Class Weight Balanced)

  Training Accuracy: 94%

  Testing Accuracy: 88%

Observations:

Same strong improvements as weighted model.

Balanced recall across classes while maintaining high accuracy.

Best trade-off between generalization, fairness across classes, and accuracy.

üìå Insights

  Baseline models (No Reg / L2 Reg) favored majority classes (happy, sadness), underperforming on minority classes (love, surprise).

  Class Weighting significantly improved minority class detection, lifting test accuracy to 88%.

  Final Choice: Logistic Regression with L2 Regularization + Class Weight Balanced is the best performing model, achieving strong accuracy while handling class imbalance.

üì¶ Tech Stack

Language: Python

Libraries: pandas, numpy, scikit-learn, nltk, TextBlob, matplotlib, seaborn, wordcloud
